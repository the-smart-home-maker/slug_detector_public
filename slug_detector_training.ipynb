{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8oOpvyv2Ace"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBKRa6gb2LhT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomContrast, RandomCrop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgxpWrP52IgF"
   },
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to load all images from the sub folder \"training_set\". The sub folder \"training_set\" itself is divided into two sub folders \"slug\" and \"no_slug\". You need to create this folder structure and fill it with example images. Example images with slugs should go into the folder \"slug\" and other images without slugs should go into \"no_slug\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgfoRN6d075r"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (192, 192)\n",
    "directory = \"training_set/\"\n",
    "\n",
    "train_dataset = image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='training',\n",
    "                                             seed=42)\n",
    "validation_dataset = image_dataset_from_directory(directory,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE,\n",
    "                                             validation_split=0.2,\n",
    "                                             subset='validation',\n",
    "                                             seed=42)\n",
    "\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(2):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWDaJpO_3RNL"
   },
   "source": [
    "# Augment data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the images will be augmented to create further training data. Augmentation will for example flip the images horizontally and vertically, will rotate them and also change the contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA9UnDDy3UlD"
   },
   "outputs": [],
   "source": [
    "def data_augmenter():\n",
    "    data_augmentation = tf.keras.Sequential()\n",
    "    data_augmentation.add(RandomFlip('horizontal_and_vertical'))\n",
    "    data_augmentation.add(RandomRotation(0.2))\n",
    "    data_augmentation.add(RandomContrast(0.2))\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = data_augmenter()\n",
    "\n",
    "for image, _ in train_dataset.take(1):\n",
    "    first_image = image[0]\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.suptitle(\"Original\")\n",
    "    plt.imshow(first_image / 255)\n",
    "    #plt.axis('off')\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.suptitle(\"Augmented\")\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(tf.cast(tf.expand_dims(first_image, 0), tf.float32),training=True)\n",
    "        plt.imshow(augmented_image[0] / 255)\n",
    "        #plt.axis('off')\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACBnXhln3qfA"
   },
   "source": [
    "# Prepare customized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iua6Zxnj3v6Q"
   },
   "outputs": [],
   "source": [
    "def slug_model(image_shape=IMG_SIZE, data_augmentation=data_augmenter()):\n",
    "      \n",
    "    input_shape = image_shape + (3,)\n",
    "    \n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
    "                                                   include_top=False, # this ensures that the top layer will not be included (as we will train this layer ourselves)\n",
    "                                                   weights='imagenet')\n",
    "    \n",
    "    # freeze the base model by making it non trainable\n",
    "    base_model.trainable = False \n",
    "\n",
    "    # create the input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape) \n",
    "    \n",
    "    # apply data augmentation to the inputs\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # data preprocessing using the same weights the model was trained on\n",
    "    x = preprocess_input(x) \n",
    "    \n",
    "    # set training to False to avoid keeping track of statistics in the batch norm layer\n",
    "    x = base_model(x, training=False) \n",
    "    \n",
    "    # use global avg pooling to summarize the info in each channel\n",
    "    x = tfl.GlobalAveragePooling2D()(x) \n",
    "    # include dropout with probability of 0.2 to avoid overfitting\n",
    "    x = tfl.Dropout(0.2)(x)\n",
    "        \n",
    "    # use a prediction layer with two neurons for the two classes (slug, no slug)\n",
    "    outputs = tfl.Dense(1)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OX9iByOV4bNq"
   },
   "source": [
    "# Instantiate and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9s2_9wvh4eiR",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = slug_model(IMG_SIZE, data_augmentation)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "base_learning_rate = 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "initial_epochs = 5\n",
    "history = model.fit(train_dataset, validation_data=validation_dataset, epochs=initial_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_model = model.layers[4]\n",
    "base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 120\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# use binary crossentropy    \n",
    "loss_function=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Define an Adam optimizer with a learning rate of 0.1 * base_learning_rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1*base_learning_rate)\n",
    "\n",
    "# Use accuracy as evaluation metric\n",
    "metrics=['accuracy']\n",
    "\n",
    "model.compile(loss=loss_function,\n",
    "              optimizer = optimizer,\n",
    "              metrics=metrics)\n",
    "\n",
    "fine_tune_epochs = 5\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset, validation_data=validation_dataset, epochs=total_epochs, initial_epoch=history.epoch[-1],)\n",
    "\n",
    "accuracy = [0.] + history.history['accuracy'] + history_fine.history['accuracy']\n",
    "validation_accuracy = [0.] + history.history['val_accuracy'] + history_fine.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss'] + history_fine.history['loss']\n",
    "validation_loss = history.history['val_loss'] + history_fine.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(accuracy, label='Accuracy of training')\n",
    "plt.plot(validation_accuracy, label='Accuracy of validation')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Accuracy of training and validation')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Loss of training phase')\n",
    "plt.plot(validation_loss, label='Loss of validation phase')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)\n",
    "\n",
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = os.path.join(os.getcwd(), \"model\")\n",
    "version = 1\n",
    "export_path = os.path.join(MODEL_DIR, str(version))\n",
    "print('export_path = {}\\n'.format(export_path))\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n",
    "\n",
    "print('\\nSaved model:')\n",
    "!ls -l {export_path}"
   ]
  },
 ],
 "metadata": {
  "colab": {
   "name": "mobilenet_test1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
